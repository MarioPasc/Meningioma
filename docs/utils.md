# Meningioma MRI Preprocessing Pipeline Analysis and Recommendations

## Pipeline Inconsistencies and Robustness Issues

* **Lack of intensity normalization:** The current pipeline does not perform any intensity normalization across scans. MRI intensity scales vary widely between scanners and sessions. Without normalization, the pre-trained nnUNet (from BraTS-MEN 2023) may see inconsistent intensity distributions, hurting segmentation accuracy. This is a known issue in multi-center MRI; studies show that applying intensity normalization (e.g. z-score per scan or histogram matching) improves feature robustness and model performance. **Recommendation:** Add an intensity normalization step (such as per-volume z-score normalization of brain voxels or a standardization to a reference histogram). This will ensure each MRI has a similar intensity range and distribution, matching the training data expectations.

* **Dependence on ground-truth mask for certain steps:** In the pipeline code, some processing steps are skipped if a segmentation mask is not present. For example, the **casting step** (`_process_cast_volume`) and **registration** require `current_mask` – if no mask is loaded (as would be the case for new unlabeled data), the code returns without casting or registering the image. This coupling is problematic for inference-time use. Essential operations like converting the volume to float32 and spatial normalization should not depend on having a ground-truth tumor mask. **Recommendation:** Decouple these steps from the segmentation mask. Always cast the input volume to float32 (and clip or scale if needed) regardless of mask. Allow registration to run with just the image (and only apply the transform to a mask if one exists). This will make the pipeline robust for cases where no initial mask is available (e.g. during model deployment on new patients).

* **Multi-modal alignment not enforced:** The pipeline processes each MRI pulse (T1, T2, FLAIR/SUSC, etc.) independently through the steps, including **independent non-linear registration** to the atlas. The only coupling is that the T1 brain mask is reused for skull stripping other modalities. This can lead to slight misalignment between modalities. In best practice, multi-modal MRI scans of the same patient should be co-registered to each other (usually aligning all to T1) before any non-linear warping. In the current setup, T2 and other sequences might undergo a different warp than T1 (since each is registered separately to SRI24), which could shift the tumor position slightly relative to T1. **Recommendation:** Integrate a subject-level registration: e.g. perform a rigid or affine registration of secondary sequences (T2, FLAIR, etc.) to the T1 before warping to atlas. The codebase even includes an `apply_composed_transforms` function suggesting this two-step approach, but it isn’t used. Implementing this would ensure all modalities remain aligned after atlas registration, improving the consistency of multi-channel input to the segmentation model.

* **Skull stripping might remove tumor extent:** Meningiomas are extra-axial (occurring outside the brain parenchyma but inside the skull). Using a brain-extraction tool (FSL BET) or an atlas brain mask can inadvertently chop off tumor portions that lie outside the “brain” mask. The pipeline uses the T1-derived mask to strip other modalities. If a tumor extends beyond what BET considers brain, those tumor voxels will be zeroed out in all channels, which could cause the network to miss them entirely. There is no check for this scenario in the current logic. **Recommendation:** Validate the brain mask against the tumor location. For example, if a ground truth mask is present, check how much of the tumor lies outside the brain mask. If substantial, consider using a more permissive BET setting (e.g. the `-s` **“skull”** option to include dura/skull) or dilating the mask to ensure the tumor is retained. In general, one might skip strict skull stripping for meningiomas or use a different approach (e.g. keeping an “head” mask that includes tumor). Ensuring the tumor isn’t erased is crucial – a possible enhancement is to intersect the initial tumor mask with the brain mask and log a warning or adjust parameters if tumor parts are lost.

* **Atlas mask application bug:** In the `universal_mask` branch of brain extraction, the code creates a binary mask from the SRI24 template brain by thresholding, but uses `insideValue=0` and `outsideValue=1`. This produces an *inverted* mask (brain voxels = 0, background = 1). Applying this mask with `sitk.Mask(current_image, brain_mask)` would zero-out the brain and keep only non-brain – clearly an error. The intention was to use the atlas brain mask to keep brain tissue. **Recommendation:** Fix the binary threshold logic so that the brain region is 1 and background 0 (or simply invert the mask after thresholding). This ensures `sitk.Mask` will correctly *keep* brain tissue. This bug would severely affect results if the `universal_mask` option is used (currently it might not be, but it should be corrected for future use).

* **Lack of intermediate quality checks:** The pipeline does not include validation or logging of intermediate results beyond basic file existence warnings. For instance, after N4 bias correction, no check is done to confirm bias was reduced, and after registration, the code doesn’t verify the transform quality. If ANTs registration failed or was poor, the pipeline simply continues, which could propagate errors (e.g. a mis-registered volume). **Recommendation:** Incorporate basic validation steps. For example, after registration to the atlas, compute the overlap between the atlas brain mask and the warped image’s brain (or check that the affine transform parameters are within reasonable ranges). If a segmentation mask is available, one could check that its volume or location didn’t change drastically through processing (aside from expected atlas scaling). Logging the bias field correction outcome (e.g. mean intensity before/after) or the registration metrics (from ANTs) can help catch issues early. Such QA steps increase robustness, ensuring each preprocessing stage did what was expected.

* **Handling of anisotropic resolutions:** It’s not explicitly addressed how extremely thick-slice images are handled. The atlas registration will resample images to 1 mm, but if an MRI has, say, 5 mm slices, a direct non-linear warp might not reconstruct fine details well. Best practice in heterogeneous datasets is to harmonize resolution – either by upsampling slices to \~1 mm with interpolation or using tailored 2D models for very thick slices. **Recommendation:** As part of preprocessing, detect if the input spacing is far from 1 mm isotropic. In such cases, an intermediate resampling (or at least using a lower-resolution registration setting) might be warranted. This is a minor point, as the atlas warp does impose 1 mm spacing, but ensuring the interpolation method and any anti-aliasing are appropriate for thick slices would improve robustness.

## Missing Validation and QA Steps

In addition to the issues above, the pipeline could benefit from explicit validation steps to ensure the outputs are sane:

* **Brain mask vs. tumor check:** As noted, a check should verify that the brain-extraction mask is not inadvertently removing the lesion. For example, if a significant portion of the tumor segmentation lies outside the extracted brain, the pipeline could log a warning or automatically adjust (e.g. by rerunning BET with a higher `frac` value). This kind of validation ensures the preprocessed data still contains all regions of interest.

* **Intensity histogram check:** The pipeline currently doesn’t verify intensity ranges after each step. It would be useful to ensure that after casting and bias correction, the image intensities are within a normal range (no extreme outliers or negative values beyond expectation). A simple histogram summary or min/max clamp (if needed) could be added. For instance, after N4 correction, one could check that the image’s mean intensity in the brain is around a typical value – if not, it might indicate an issue (like a mis-scaled input).

* **Registration quality metrics:** When performing atlas registration, tools like ANTs provide metrics (e.g. cross-correlation or mutual information) and transformations. A validation step could be to ensure the transformation is not degenerate. For example, an extremely large scaling or shear in the affine component might indicate a problem. Also, because the pipeline warps the segmentation mask, one could compute the Dice overlap between the warped mask and an atlas brain mask or template tumor location (if available) to sanity-check alignment. Storing and reviewing these metrics for each case would catch cases where registration failed (e.g., if a patient had an unusual artifact causing mis-registration).

* **Consistent output geometry:** The final outputs should be in a consistent orientation and geometry expected by nnUNet. The code aligns to SRI24, which yields a consistent spatial orientation and resolution for all cases. It might be prudent to also ensure consistent matrix size (e.g., BraTS typically had 240x240x155 after preprocessing). If the atlas yields varying dimensions (unlikely, as SRI24 is fixed at 1 mm in a defined FoV), one might pad or crop to a standard size. A validation step can confirm that all output volumes have the same shape and resolution before feeding to nnUNet, avoiding any downstream shape mismatches.

* **Log intermediate outputs (optional):** While the pipeline has an option to save intermediates, enabling this for a few test cases and visually inspecting the outputs at each step is a good practice. For instance, checking the N4-corrected image and brain mask overlay, or the atlas-registered image with an atlas brain outline, can qualitatively validate the processing. Automating such checks is hard, but even a simple montage saved for each patient (if in debug mode) could assist manual QA.

By adding these validation steps, any irregularities in preprocessing can be caught early, rather than only noticing a problem after the segmentation model fails on a case.

## Comparison to State-of-the-Art Preprocessing Practices

Overall, the pipeline includes several components that are in line with modern best practices for brain MRI segmentation, but it also misses a few. A comparison with common pipelines (like those used in BraTS and other challenges) is as follows:

* **Spatial co-registration and standard space:** It is standard to co-register all MRI modalities for a patient to a common space. BraTS challenges, for example, distributed multi-modal data already aligned to each other and to an atlas. In BraTS 2021, all scans were affinely co-registered to the SRI24 brain atlas and resampled to 1 mm isotropic resolution, resulting in a uniform image shape. The given pipeline does perform atlas registration (using SRI24) and resampling, which is good. However, as noted, BraTS would typically do one registration per patient (using one modality as reference) – our pipeline’s independent registrations per modality is a deviation from that ideal. Nonetheless, using SRI24 atlas provides a consistent orientation and spacing, which matches the *spatial standardization* that state-of-the-art methods often employ. Some pipelines use the MNI152 atlas instead, but the choice of atlas is less important than ensuring all data share a common reference space.

* **Skull stripping:** Removing non-brain tissues is a common step in brain tumor segmentation pipelines, as it focuses the model on the intracranial content. The BraTS preprocessing pipeline explicitly skull-stripped all modalities after registration. Our pipeline does this via FSL BET or atlas masking. This is aligned with best practice for intraparenchymal tumors (gliomas), but for meningiomas (which often reside on the brain’s surface), skull stripping must be done carefully. State-of-the-art approaches would either fine-tune the skull stripping or sometimes even skip it if the tumor routinely lies outside the brain mask. In literature, skull stripping is usually performed (BraTS provided skull-stripped data), so our pipeline following suit is reasonable – with the earlier caveat about ensuring tumor inclusion.

* **Bias field correction:** The N4 bias correction step is a well-established preprocessing step for MRI. It corrects intensity inhomogeneities (field shading) and was used in many challenge-winning solutions. For example, BraTS organizers often recommended N4 on T1 post-contrast images. The pipeline’s use of N4 (with a brain mask) on each MRI volume is a positive aspect and reflects state-of-the-art practice. Bias correction makes intensity normalization more reliable and is considered essential for heterogeneous data.

* **Intensity normalization:** This is one area where the pipeline is currently lacking. Virtually all modern MRI segmentation methods perform some form of intensity normalization. The nnU-Net framework, for instance, applies a simple z-score normalization per channel (clipping extreme intensities and then subtracting mean and dividing by std dev of the foreground) as part of its preprocessing. The BraTS 2020+ data releases also had each modality normalized (often by subtracting the mean and dividing by the std of brain voxels). Additionally, research studies have compared normalization techniques (Nyul, WhiteStripe, z-score) and found that they improve the robustness of features and outcomes. Thus, not having any intensity normalization in the pipeline is a deviation from best practices. It likely would impair the nnUNet model which expects inputs on a similar intensity scale as its training data. In summary, intensity normalization is strongly recommended (and in literature, even simple z-score per scan is effective and widely used).

* **Resolution harmonization:** The pipeline does address resolution by registering to an atlas at 1 mm. Best practices in challenges like BraTS ensured all data were resampled to 1x1x1 mm³ voxels. nnU-Net similarly will resample images to a target spacing during training/inference. By using the atlas as the reference, our pipeline ensures all outputs have the same resolution (the SRI24 atlas is provided at 1 mm isotropic). This is on par with state-of-the-art handling of differing voxel sizes. One note is that some pipelines might choose an intermediate resolution if 1 mm is much higher than the native (to avoid interpolation artifacts), but since BraTS-Men model was likely trained on 1 mm data, matching that is appropriate.

* **Modality-specific handling:** In literature, MRI (T1, T2, FLAIR, etc.) and CT require different pre-processing. Our pipeline is labeled for "RM" (resonancia magnética, MRI) and "TC" (tomografía computarizada, CT). However, the CT branch is not implemented. State-of-the-art segmentation of brain tumors from MRI uses the aforementioned steps. If CT were to be used (perhaps for calcifications or bone involvement), typically one would at least perform an intensity normalization (CT has absolute units: Hounsfield Units – so one might window the CT and normalize), and a registration to the MRI or atlas (rigid, since CT and MRI alignment requires only an affine transform). The pipeline currently skips CT processing with a placeholder. This is a gap if CT data are part of the dataset. Best practice would be to implement a similar pipeline for CT: e.g., convert to NIfTI, maybe denoise, then rigidly register CT to the corresponding MRI (or to atlas via MRI as an intermediary), and possibly skull-strip (though CT skull stripping is also non-trivial, since skull is visible). While literature on meningioma challenges hasn’t emphasized CT as much as MRI, if CT is used, a robust preprocessing akin to MRI (minus bias correction, which isn’t needed for CT) would be ideal.

* **Denoising:** The pipeline includes an optional SUSAN denoising step. Many modern pipelines do not explicitly denoise MRI (since modern scanners and subsequent processing make noise less of an issue, and aggressive denoising can blur important details). However, in cases of very noisy images (older scans or low-field MRI), denoising can help. SUSAN is a noise-reduction filter that preserves edges, and it’s a reasonable choice. In the BraTS context, denoising was not a highlighted step (the bias field correction and normalization were considered more important). Thus, denoising is optional – including it as a configurable step (as done in the pipeline) is fine. This aligns with a cautious approach: allow it if needed, but it can be turned off to preserve maximum detail for the network.

In summary, the pipeline aligns with state-of-the-art practices in terms of **bias correction, atlas registration, skull stripping, and data type standardization**, but it is missing **intensity normalization** and a more **robust multi-modal alignment** strategy. Challenges like BraTS have demonstrated the importance of those missing pieces: co-registration of modalities and intensity normalization were part of the “standard preprocessing pipeline”. By incorporating these, the pipeline would be on par with what top-performing teams use for heterogeneous MRI segmentation tasks.

## Recommendations and Enhancements

Considering the analysis above, here is a concise list of improvements to implement, in order of priority:

* **Incorporate Intensity Normalization:** Add a step after bias correction (or at the very end of preprocessing) to normalize intensities of each volume. A simple and effective approach is to use z-score normalization (compute mean and standard deviation of intensities inside the brain mask, subtract the mean and divide by std). This will greatly reduce scanner-specific intensity differences. Alternatively, one could perform a histogram matching to a reference (for example, match each T1 to a template T1 histogram), but the z-score per scan is straightforward and has been used successfully by nnUNet and BraTS winners. This enhancement will help the pre-trained model generalize better to new data.

* **Improve Multi-modal Registration:** To ensure all MRI modalities are aligned, consider using a two-step registration: first register secondary modalities (T2, FLAIR/SUSC) to T1 (within the patient), then apply the same atlas transform from T1 to those volumes. The codebase already contains utilities for this (e.g., storing transform parameters and applying composite transforms). By doing this, you ensure that the relative placement of tumor and anatomy is consistent across channels. This matches how datasets like BraTS were prepared (all modalities co-registered before atlas mapping). It will prevent issues where, say, a tumor edge in T2 is one voxel off from the T1 due to separate warps.

* **Fix the Atlas Mask Logic:** Correct the universal atlas mask usage by ensuring the binary mask is generated properly (brain = 1). If the intention is to sometimes use an atlas brain mask instead of BET (perhaps to have a “perfect” brain mask in atlas space), make sure that mask is applied correctly. After fixing the inversion bug, test the `universal_mask` option on a case to confirm it yields a proper skull-stripped image. This could serve as an alternative skull stripping method: register T1 to atlas, then use atlas brain mask to strip – which might be more stable than BET for some cases (though again, be mindful of external tumor).

* **Make Casting unconditional:** Modify `_process_cast_volume` to cast the image to float32 even if no segmentation mask is present. You could simply skip mask casting if mask is None, but still cast the image. This way, at inference time the MRI will be in the correct type for nnUNet (which typically expects float32 inputs). This is a minor code change but improves robustness.

* **Add a Preprocessing QA Routine:** It’s beneficial to implement a small function that runs after preprocessing each patient (or as part of it) to verify outputs. For example, ensure that `final_image_path` was produced and is readable, that its dimensions and spacing match the atlas specs, and (if a segmentation was input) that the final mask overlaps with the final image. Even logging summary statistics (mean intensity, etc.) for each output can help detect anomalies across a dataset. If any check fails, the pipeline could flag that patient for manual review. This addition will catch issues early in a large batch processing scenario.

* **Handle CT data (if needed):** If the project intends to use the CT (`TC`) images for segmentation or analysis, implement the CT preprocessing branch (`tc_preprocessing`). Typically, for brain CT one would: convert to NIfTI, possibly apply a smoothing filter (CT can be noisy), and perform an affine registration to the MRI or atlas (since CT has a different contrast, a deformable registration might not be necessary or could be done via a different modality conversion, e.g. registration using mutual information). Also, intensity normalization for CT could be simply clipping to a certain HU window (e.g. brain window \~\[0,80] HU for soft tissue) and then scaling to 0–1. Right now, the pipeline logs that TC processing is “not yet implemented” – addressing this will complete the pipeline for all modalities. Even if the nnUNet model is MRI-only, having co-registered CT could be useful for future analysis or multimodal experiments.

* **Skull stripping adjustments for meningiomas:** Consider an enhancement in how skull stripping is done for cases with large extra-axial tumor: for example, BET offers a `-S` option (smooth bias) and `-B` for bias remove, but more relevant is the `-s` option which outputs the *skull* image. Using `skull=True` in the BET call (as the code allows via the `skull` parameter) actually keeps the skull in the output (so it extracts brain+skull together). If tumors on the dura are being removed by normal BET, one strategy could be to run BET with `skull=True` to get a mask that includes the skull/meninges – this mask would definitely include the tumor. One could then possibly remove only the external air/background while keeping the tumor. This is an advanced tweak: essentially generating a mask of the head (not just brain) and using that. The pipeline already passes a `skull` parameter to BET (default False); setting it True might yield better inclusion of tumor for some patients. It might be worth experimenting and perhaps making this an automatic choice if the tumor is mostly outside the normal brain mask. At minimum, document this possibility so users of the pipeline can toggle it if needed.

* **Documentation and logging:** As a final recommendation, clearly document these preprocessing steps and any assumptions (like “T1 must be present and of reasonable quality”). Encourage users to inspect a few processed examples. Good logging (the pipeline already uses `logger.info` and warnings) should be maintained – e.g., logging the use of T1 mask for other sequences is helpful. Consider adding a log entry if intensity normalization is applied (mean/std values) for transparency. These practices align the pipeline implementation with research publication standards and make it easier to troubleshoot if the segmentation results are suboptimal.

By implementing the above enhancements, the preprocessing pipeline will be more in line with state-of-the-art practices and more robust to real-world clinical data variability. These changes aim to improve the consistency of the MRI inputs fed to the segmentation model, which in turn should boost the accuracy and reliability of meningioma segmentation results.

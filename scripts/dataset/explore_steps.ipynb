{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Processing T1\n",
      "=====================================\n",
      "Input volume shape: (416, 512, 192)\n",
      "Input hdr fields:\n",
      " - dimensions: 3\n",
      " - sizes: [416 512 192]\n",
      " - space directions: [[ 0.46754256838748026 -0.01235863904309036  0.03126936658522083]\n",
      " [ 0.01877844950535475  0.45759081350102976 -0.09992286892218787]\n",
      " [-0.05533471886129857  0.20022161611266281  0.9065039159753452 ]]\n",
      " - kinds: ['domain', 'domain', 'domain']\n",
      " - space origin: [ -97.39358329164699 -146.91877981590994  -70.622476993478  ]\n",
      "Input volume shape: (416, 512, 192)\n",
      "Input hdr fields:\n",
      " - dimensions: 3\n",
      " - sizes: [416 512 192]\n",
      " - space directions: [[ 0.46754256838748026 -0.01235863904309036  0.03126936658522083]\n",
      " [ 0.01877844950535475  0.45759081350102976 -0.09992286892218787]\n",
      " [-0.05533471886129857  0.20022161611266281  0.9065039159753452 ]]\n",
      " - kinds: ['domain', 'domain', 'domain']\n",
      " - space origin: [ -97.39358329164699 -146.91877981590994  -70.622476993478  ]\n",
      "[N4] Starting bias field correction with the following params:\n",
      "  shrink_factor=4, max_iterations=50, bias_field_fwhm=0.15, control_points=[4, 4, 4]\n",
      "[N4] Finished correction at level 4, last convergence measurement=0.0013327518245205283\n",
      "=====================================\n",
      "Processing T2\n",
      "=====================================\n",
      "Input volume shape: (320, 320, 21)\n",
      "Input hdr fields:\n",
      " - dimensions: 3\n",
      " - sizes: [320 320  21]\n",
      " - space directions: [[ 0.6857291003016379  -0.01812600392986588  0.04586173765832392]\n",
      " [ 0.02754172594118698  0.671133193134844   -0.14655354108587557]\n",
      " [-0.39269799838095887  1.4209275749123824   6.43325349172407   ]]\n",
      " - kinds: ['domain', 'domain', 'domain']\n",
      " - space origin: [-111.1677555406     -131.91836989255006  -45.44134392229302]\n",
      "Input volume shape: (320, 320, 21)\n",
      "Input hdr fields:\n",
      " - dimensions: 3\n",
      " - sizes: [320 320  21]\n",
      " - space directions: [[ 0.6857291003016379  -0.01812600392986588  0.04586173765832392]\n",
      " [ 0.02754172594118698  0.671133193134844   -0.14655354108587557]\n",
      " [-0.39269799838095887  1.4209275749123824   6.43325349172407   ]]\n",
      " - kinds: ['domain', 'domain', 'domain']\n",
      " - space origin: [-111.1677555406     -131.91836989255006  -45.44134392229302]\n",
      "[N4] Starting bias field correction with the following params:\n",
      "  shrink_factor=4, max_iterations=50, bias_field_fwhm=0.15, control_points=[4, 4, 4]\n",
      "[N4] Finished correction at level 4, last convergence measurement=0.0009655076428316534\n",
      "=====================================\n",
      "Processing SUSC\n",
      "=====================================\n",
      "Input volume shape: (264, 384, 21)\n",
      "Input hdr fields:\n",
      " - dimensions: 3\n",
      " - sizes: [264 384  21]\n",
      " - space directions: [[ 0.623390091183307   -0.01647818539078714  0.04169248878029447]\n",
      " [ 0.02503793267380633  0.6101210846680394  -0.1332304918962505 ]\n",
      " [-0.39269799838095115  1.4209275749123542   6.433253491723945  ]]\n",
      " - kinds: ['domain', 'domain', 'domain']\n",
      " - space origin: [ -84.139198451318    -142.40534740442993   -41.475186545619025]\n",
      "Input volume shape: (264, 384, 21)\n",
      "Input hdr fields:\n",
      " - dimensions: 3\n",
      " - sizes: [264 384  21]\n",
      " - space directions: [[ 0.623390091183307   -0.01647818539078714  0.04169248878029446]\n",
      " [ 0.02503793267380633  0.6101210846680394  -0.1332304918962505 ]\n",
      " [-0.39269799838095115  1.4209275749123542   6.433253491723945  ]]\n",
      " - kinds: ['domain', 'domain', 'domain']\n",
      " - space origin: [ -84.139198451318    -142.40534740442993   -41.475186545619025]\n",
      "[N4] Starting bias field correction with the following params:\n",
      "  shrink_factor=4, max_iterations=50, bias_field_fwhm=0.15, control_points=[4, 4, 4]\n",
      "[N4] Finished correction at level 4, last convergence measurement=0.0013108483981341124\n"
     ]
    }
   ],
   "source": [
    "from Meningioma.preprocessing.tools.remove_extra_channels import remove_first_channel\n",
    "from Meningioma.preprocessing.tools.casting import cast_volume_and_mask\n",
    "from Meningioma.preprocessing.tools.nrrd_to_nifti import nifti_write_3d\n",
    "from Meningioma.preprocessing.tools.denoise_susan import denoise_susan\n",
    "from Meningioma.preprocessing.tools.bias_field_corr_n4 import n4_bias_field_correction, generate_brain_mask_sitk\n",
    "from Meningioma.preprocessing.tools.skull_stripping.fsl_bet import fsl_bet_brain_extraction\n",
    "\n",
    "# Disable GPU usage entirely - slower but more reliable\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Use CPU only\n",
    "\n",
    "import os\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = \"/home/mariopasc/Python/Datasets/Meningiomas\"\n",
    "ATLAS = \"/home/mariopasc/Python/Datasets/Meningiomas/ATLAS/sri24_spm8/templates/T1_brain.nii\"\n",
    "INPUT_PATH = os.path.join(PATH, \"Meningioma_Adquisition\")\n",
    "OUTPUT_PATH = os.path.join(PATH, \"output\")\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "MODALITY = \"RM\"\n",
    "PULSES = [\"T1\", \"T2\", \"SUSC\"]\n",
    "PATIENT = \"1\"\n",
    "\n",
    "data = {}\n",
    "for pulse in PULSES:\n",
    "    vol_path = os.path.join(INPUT_PATH, MODALITY, pulse, f\"P{PATIENT}\", f\"{pulse}_P{PATIENT}.nrrd\")\n",
    "    seg_path = os.path.join(INPUT_PATH, MODALITY, pulse, f\"P{PATIENT}\", f\"{pulse}_P{PATIENT}_seg.nrrd\")\n",
    "    data[pulse] = {\"vol\": vol_path, \"seg\": seg_path}\n",
    "\n",
    "    print(\"=====================================\")\n",
    "    print(f\"Processing {pulse}\")\n",
    "    print(\"=====================================\")\n",
    "\n",
    "    # Load and save paths\n",
    "    vol_path = data[pulse][\"vol\"]\n",
    "    seg_path = data[pulse][\"seg\"]\n",
    "    \n",
    "    # Remove first channel\n",
    "    vol, hdr = remove_first_channel(nrrd_path=vol_path, channel=0, verbose=True)\n",
    "    seg, hdr_seg = remove_first_channel(nrrd_path=seg_path, channel=0, verbose=True)\n",
    "    # Cast volume and mask\n",
    "    vol, seg = cast_volume_and_mask(volume_img=vol, mask_img=seg)\n",
    "\n",
    "    # n4 bias field correction\n",
    "    _, mask_brain = generate_brain_mask_sitk(volume_sitk=vol)\n",
    "    vol = n4_bias_field_correction(volume_sitk=vol, verbose=True)\n",
    "\n",
    "    # save files\n",
    "    nifti_write_3d([vol, hdr], os.path.join(OUTPUT_PATH, f\"{pulse}_P{PATIENT}\"))\n",
    "    nifti_write_3d([seg, hdr_seg], os.path.join(OUTPUT_PATH, f\"{pulse}_P{PATIENT}_seg\"))\n",
    "    # Save\n",
    "    data[pulse] = {\n",
    "        \"input_paths\": {\n",
    "            \"vol\": vol_path,\n",
    "            \"seg\": seg_path,\n",
    "        },\n",
    "        \"arrays\": {\n",
    "            \"vol\": sitk.GetArrayFromImage(vol),\n",
    "            \"seg\": sitk.GetArrayFromImage(seg),\n",
    "        },\n",
    "        \"output_paths\": {\n",
    "            \"vol\": os.path.join(OUTPUT_PATH, f\"{pulse}_P{PATIENT}.nii.gz\"),\n",
    "            \"seg\": os.path.join(OUTPUT_PATH, f\"{pulse}_P{PATIENT}_seg.nii.gz\"),\n",
    "        }\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading atlas from /home/mariopasc/Python/Datasets/Meningiomas/ATLAS/sri24_spm8/templates/T1_brain.nii\n",
      "Using common registration shape: [160, 192, 160]\n",
      "\n",
      "===== Registering T1 to ATLAS =====\n",
      "Original T1 shape: (416, 512, 192), spacing: (0.46875, 0.46875, 0.9300000071525574)\n",
      "Running first registration pass...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "Running second registration pass...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "Applying transformation to segmentation...\n",
      "\n",
      "===== Registering T2 to ATLAS =====\n",
      "Original T2 shape: (320, 320, 21), spacing: (0.6875, 0.6875, 6.599999904632568)\n",
      "Running first registration pass...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "Running second registration pass...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "Applying transformation to segmentation...\n",
      "\n",
      "===== Registering SUSC to ATLAS =====\n",
      "Original SUSC shape: (264, 384, 21), spacing: (0.625, 0.625, 6.599999904632568)\n",
      "Running first registration pass...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "Running second registration pass...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "Applying transformation to segmentation...\n",
      "\n",
      "Registration complete. All files saved in: /home/mariopasc/Python/Datasets/Meningiomas/output/registered\n"
     ]
    }
   ],
   "source": [
    "from Meningioma.preprocessing.tools.registration import SynthMorphRegister\n",
    "\n",
    "# Initialize the registration module\n",
    "registrator = SynthMorphRegister(output_dir=os.path.join(OUTPUT_PATH, \"registered\"))\n",
    "\n",
    "# Register all modalities to the atlas\n",
    "data = registrator.register_all_to_atlas(\n",
    "    data_dict=data,\n",
    "    atlas_path=ATLAS,\n",
    "    patient_id=PATIENT\n",
    ")\n",
    "\n",
    "# Visualize the results\n",
    "registrator.visualize_results(\n",
    "    data_dict=data,\n",
    "    pulses=PULSES,\n",
    "    patient_id=PATIENT,\n",
    "    # Optional custom slice indices\n",
    "    # slice_indices={'axial': 80, 'sagittal': 95, 'coronal': 90}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registration test with existing data dictionary\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import voxelmorph as vxm\n",
    "\n",
    "# Create a registration test directory\n",
    "TEST_OUTPUT_DIR = os.path.join(OUTPUT_PATH, \"registration_test\")\n",
    "os.makedirs(TEST_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Define model path and download if needed\n",
    "SYNTHMORPH_MODEL_PATH = os.path.join(TEST_OUTPUT_DIR, \"shapes-dice-vel-3-res-8-16-32-256f.h5\")\n",
    "if not os.path.exists(SYNTHMORPH_MODEL_PATH):\n",
    "    print(f\"Downloading SynthMorph model to {SYNTHMORPH_MODEL_PATH}\")\n",
    "    !curl -o {SYNTHMORPH_MODEL_PATH} https://surfer.nmr.mgh.harvard.edu/ftp/data/voxelmorph/synthmorph/shapes-dice-vel-3-res-8-16-32-256f.h5\n",
    "\n",
    "def normalize_volume(volume):\n",
    "    \"\"\"Normalize volume to [0,1] range.\"\"\"\n",
    "    volume = volume.astype(np.float32)\n",
    "    volume -= volume.min()\n",
    "    volume /= volume.max()\n",
    "    return volume\n",
    "\n",
    "def resize_to_model_compatible(img, target_shape=None):\n",
    "    \"\"\"Resize image to dimensions compatible with the model (divisible by 16).\"\"\"\n",
    "    if target_shape is None:\n",
    "        # Make dimensions divisible by 16\n",
    "        shape = img.GetSize()\n",
    "        target_shape = [((dim + 15) // 16) * 16 for dim in shape]\n",
    "\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetSize(target_shape)\n",
    "    resample.SetOutputOrigin(img.GetOrigin())\n",
    "    spacing = [orig_sz * orig_sp / targ_sz for orig_sz, orig_sp, targ_sz in \n",
    "              zip(img.GetSize(), img.GetSpacing(), target_shape)]\n",
    "    resample.SetOutputSpacing(spacing)\n",
    "    resample.SetOutputDirection(img.GetDirection())\n",
    "    resample.SetInterpolator(sitk.sitkLinear)\n",
    "    resample.SetDefaultPixelValue(0)\n",
    "    \n",
    "    return resample.Execute(img), target_shape\n",
    "\n",
    "# Load the atlas\n",
    "print(f\"Loading atlas from {ATLAS}\")\n",
    "atlas_img = sitk.ReadImage(ATLAS)\n",
    "\n",
    "# Common shape for all registrations\n",
    "common_shape = [160, 192, 160]  # Should be divisible by 16\n",
    "print(f\"Using common registration shape: {common_shape}\")\n",
    "\n",
    "# Resize atlas to common shape\n",
    "atlas_resampled, _ = resize_to_model_compatible(atlas_img, common_shape)\n",
    "atlas_array = sitk.GetArrayFromImage(atlas_resampled)\n",
    "atlas_norm = normalize_volume(atlas_array)[np.newaxis, ..., np.newaxis]\n",
    "\n",
    "# Initialize the model\n",
    "print(\"Initializing registration model...\")\n",
    "model = vxm.networks.VxmDense(\n",
    "    nb_unet_features=([256] * 4, [256] * 6),\n",
    "    int_steps=5,\n",
    "    int_resolution=2,\n",
    "    svf_resolution=2,\n",
    "    inshape=common_shape,\n",
    ")\n",
    "model = tf.keras.Model(model.inputs, model.references.pos_flow)\n",
    "model.load_weights(SYNTHMORPH_MODEL_PATH)\n",
    "\n",
    "# Function to register one modality to atlas\n",
    "def register_to_atlas(pulse, pulse_data, atlas_norm):\n",
    "    print(f\"\\n==== Registering {pulse} to atlas ====\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create pulse output directory\n",
    "    pulse_output_dir = os.path.join(TEST_OUTPUT_DIR, pulse)\n",
    "    os.makedirs(pulse_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the moving image\n",
    "    moving_img = sitk.ReadImage(pulse_data[\"output_paths\"][\"vol\"])\n",
    "    \n",
    "    # Original shape and spacing\n",
    "    orig_shape = moving_img.GetSize()\n",
    "    orig_spacing = moving_img.GetSpacing()\n",
    "    print(f\"Original {pulse} shape: {orig_shape}, spacing: {orig_spacing}\")\n",
    "    \n",
    "    # Resize to common shape\n",
    "    moving_resampled, _ = resize_to_model_compatible(moving_img, common_shape)\n",
    "    moving_array = sitk.GetArrayFromImage(moving_resampled)\n",
    "    moving_norm = normalize_volume(moving_array)[np.newaxis, ..., np.newaxis]\n",
    "    \n",
    "    # First registration pass\n",
    "    print(f\"Running first registration pass...\")\n",
    "    warp_field = model.predict((moving_norm, atlas_norm))\n",
    "    \n",
    "    # Apply transformation\n",
    "    moved = vxm.layers.SpatialTransformer(fill_value=0)((moving_norm, warp_field))\n",
    "    \n",
    "    # Second registration pass\n",
    "    print(f\"Running second registration pass...\")\n",
    "    resid = model.predict((moved, atlas_norm))\n",
    "    combined_warp = vxm.layers.ComposeTransform()((warp_field, resid))\n",
    "    final_moved = vxm.layers.SpatialTransformer(fill_value=0)((moving_norm, combined_warp))\n",
    "    \n",
    "    # Also register the segmentation mask\n",
    "    seg_img = sitk.ReadImage(pulse_data[\"output_paths\"][\"seg\"])\n",
    "    seg_resampled, _ = resize_to_model_compatible(seg_img, common_shape)\n",
    "    seg_array = sitk.GetArrayFromImage(seg_resampled)\n",
    "    seg_norm = normalize_volume(seg_array)[np.newaxis, ..., np.newaxis]\n",
    "    \n",
    "    # Apply the same transformation to the segmentation with nearest neighbor interpolation\n",
    "    seg_moved = vxm.layers.SpatialTransformer(\n",
    "        fill_value=0, \n",
    "        interp_method='nearest'\n",
    "    )((seg_norm, combined_warp))\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Registration completed in {elapsed:.2f} seconds\")\n",
    "    \n",
    "    # Save the warped volume\n",
    "    moved_path = os.path.join(pulse_output_dir, f\"{pulse}_P{PATIENT}_registered_to_atlas.nii.gz\")\n",
    "    moved_sitk = sitk.GetImageFromArray(np.squeeze(final_moved[0]))\n",
    "    moved_sitk.SetSpacing(moving_resampled.GetSpacing())\n",
    "    moved_sitk.SetOrigin(moving_resampled.GetOrigin())\n",
    "    moved_sitk.SetDirection(moving_resampled.GetDirection())\n",
    "    sitk.WriteImage(moved_sitk, moved_path)\n",
    "    \n",
    "    # Save the segmentation\n",
    "    seg_moved_path = os.path.join(pulse_output_dir, f\"{pulse}_P{PATIENT}_seg_registered_to_atlas.nii.gz\")\n",
    "    seg_moved_sitk = sitk.GetImageFromArray(np.squeeze(seg_moved[0]))\n",
    "    seg_moved_sitk.SetSpacing(seg_resampled.GetSpacing())\n",
    "    seg_moved_sitk.SetOrigin(seg_resampled.GetOrigin())\n",
    "    seg_moved_sitk.SetDirection(seg_resampled.GetDirection())\n",
    "    sitk.WriteImage(seg_moved_sitk, seg_moved_path)\n",
    "    \n",
    "    # Save the warp field\n",
    "    warp_path = os.path.join(pulse_output_dir, f\"{pulse}_P{PATIENT}_to_atlas_warp.nii.gz\")\n",
    "    warp_sitk = sitk.GetImageFromArray(np.squeeze(combined_warp[0]), isVector=True)\n",
    "    warp_sitk.SetSpacing(moving_resampled.GetSpacing())\n",
    "    warp_sitk.SetOrigin(moving_resampled.GetOrigin())\n",
    "    warp_sitk.SetDirection(moving_resampled.GetDirection())\n",
    "    sitk.WriteImage(warp_sitk, warp_path)\n",
    "    \n",
    "    # Update data dictionary with registration paths\n",
    "    pulse_data[\"registered_paths\"] = {\n",
    "        \"vol\": moved_path,\n",
    "        \"seg\": seg_moved_path,\n",
    "        \"warp\": warp_path\n",
    "    }\n",
    "    \n",
    "    print(f\"Results saved to {pulse_output_dir}\")\n",
    "    return {\n",
    "        \"moved_path\": moved_path, \n",
    "        \"seg_path\": seg_moved_path,\n",
    "        \"warp_path\": warp_path, \n",
    "        \"elapsed_time\": elapsed\n",
    "    }\n",
    "\n",
    "# Run registration for all pulses\n",
    "results = {}\n",
    "for pulse in PULSES:\n",
    "    results[pulse] = register_to_atlas(pulse, data[pulse], atlas_norm)\n",
    "\n",
    "# Create visualization function\n",
    "def visualize_all_registrations(data_dict, pulses, output_dir):\n",
    "    \"\"\"Visualize registration results for all pulses.\"\"\"\n",
    "    # Set up figure\n",
    "    fig, axes = plt.subplots(3, len(pulses), figsize=(5*len(pulses), 12))\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "    \n",
    "    # Set figure background to black\n",
    "    fig.patch.set_facecolor('black')\n",
    "    \n",
    "    # Load all registered images\n",
    "    images = []\n",
    "    for pulse in pulses:\n",
    "        img_path = data_dict[pulse][\"registered_paths\"][\"vol\"]\n",
    "        img = sitk.ReadImage(img_path)\n",
    "        img_array = sitk.GetArrayFromImage(img)\n",
    "        images.append(img_array)\n",
    "    \n",
    "    # Find global min and max for consistent windowing\n",
    "    global_min = min(img.min() for img in images)\n",
    "    global_max = max(img.max() for img in images)\n",
    "    \n",
    "    # Get middle slice indices for each view\n",
    "    i, j, k = (images[0].shape[0] // 2, \n",
    "              images[0].shape[1] // 2, \n",
    "              images[0].shape[2] // 2)\n",
    "    \n",
    "    # Plot each pulse type in columns\n",
    "    for col, pulse in enumerate(pulses):\n",
    "        img_array = images[col]\n",
    "        \n",
    "        # Axial view (top row)\n",
    "        ax = axes[0, col]\n",
    "        ax.imshow(img_array[i, :, :], cmap='gray', vmin=global_min, vmax=global_max)\n",
    "        ax.set_title(f\"{pulse} - Axial\", color='white', fontsize=14)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Sagittal view (middle row)\n",
    "        ax = axes[1, col]\n",
    "        ax.imshow(img_array[:, :, k], cmap='gray', vmin=global_min, vmax=global_max)\n",
    "        ax.set_title(f\"{pulse} - Sagittal\", color='white', fontsize=14)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Coronal view (bottom row)\n",
    "        ax = axes[2, col]\n",
    "        ax.imshow(img_array[:, j, :], cmap='gray', vmin=global_min, vmax=global_max)\n",
    "        ax.set_title(f\"{pulse} - Coronal\", color='white', fontsize=14)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the visualization\n",
    "    output_path = os.path.join(output_dir, f\"registered_visualization_P{PATIENT}.png\")\n",
    "    plt.savefig(output_path, facecolor='black', bbox_inches='tight', dpi=150)\n",
    "    print(f\"Visualization saved to: {output_path}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Visualize the results\n",
    "fig = visualize_all_registrations(data, PULSES, TEST_OUTPUT_DIR)\n",
    "plt.show()\n",
    "\n",
    "# Print summary of registration results\n",
    "print(\"\\n==== Registration Results Summary ====\")\n",
    "for pulse, result in results.items():\n",
    "    print(f\"{pulse} Registration:\")\n",
    "    print(f\"  - Warped image: {result['moved_path']}\")\n",
    "    print(f\"  - Warped segmentation: {result['seg_path']}\")\n",
    "    print(f\"  - Warp field: {result['warp_path']}\")\n",
    "    print(f\"  - Time taken: {result['elapsed_time']:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meningiomas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
